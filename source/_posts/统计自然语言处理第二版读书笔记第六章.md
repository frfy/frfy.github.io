---
title: 统计自然语言处理第二版笔记第六章(一)
tags:
	- NLP
	- MACHINELEARNING
---
概率图模型（probabilistic graphical models）在概率模型的基础上，使用了基于图的方法来表示概率分布（或者概率密度、密度函数），是一种通用化的不确定性知识表示和处理方法。
<!--more-->




## 概率图模型
图模型
		有向图模型	
						静态贝叶斯网络
						动态贝叶斯网络
											隐马尔科夫模型
											卡尔曼滤波器
		无向图模型		
						马尔科夫网络
											吉布斯/玻尔兹曼机
											条件随机场

动态贝叶斯网络（dynamic Bayesian networks, DBN）用于处理随时间变化的动态系统中的推断和预测问题。
		隐马尔可夫模型（hidden Markov model, HMM）在语音识别、汉语自动分词与词性标注和统计机器翻译等若干语音语言处理任务中得到了广泛应用。
		卡尔曼滤波器则在信号处理领域有广泛的用途。

马尔可夫网络（Markov network）又称马尔可夫随机场（Markov random field, MRF）。
		马尔可夫网络下的条件随机场（conditional random field, CRF）广泛应用于自然语言处理中的序列标注、特征选择、机器翻译等任务。
		波尔兹曼机（Boltzmann machine）近年来被用于依存句法分析［Garg and Henderson, 2011］和语义角色标注等。


朴素贝叶斯&rarr;——[序列]——>隐马尔科夫模型————[一般图]————>生成式有向图模型
	|						|								|
在一定条件下			在一定条件下					在一定条件下		
	|						|								|
	V						V								V
逻辑回归——[序列]——>线性链式条件随机场————[一般图]————>通用条件随机场

横向：由点到线（序列结构）、到面（图结构）。
	以朴素贝叶斯模型为基础的隐马尔可夫模型用于处理线性序列问题，有向图模型用于解决一般图问题；
	以逻辑回归模型（即自然语言处理中ME模型）为基础的线性链式条件随机场用于解决“线式”序列问题，通用条件随机场用于解决一般图问题。

纵向：在一定条件下生成式模型（generative model）转变为判别式模型（discriminative model），
	朴素贝叶斯模型演变为逻辑回归模型，
	隐马尔可夫模型演变为线性链式条件随机场，
	生成式有向图模型演变为通用条件随机场。

生成式模型（或称产生式模型）与区分式模型（或称判别式模型）的本质区别在于模型中观测序列x和状态序列y之间的决定关系，前者假设y决定x，后者假设x决定y。

生成模型以“状态（输出）序列y按照一定的规律生成观测（输入）序列x”为假设，针对联合分布p（x, y）进行建模，并且通过估计使生成概率最大的生成序列来获取y。生成式模型是所有变量的全概率模型，因此可以模拟（“生成”）所有变量的值。在这类模型中一般都有严格的独立性假设，特征是事先给定的，并且特征之间的关系直接体现在公式中。这类模型的优点是：处理单类问题时比较灵活，模型变量之间的关系比较清楚，模型可以通过增量学习获得，可用于数据不完整的情况。其弱点在于模型的推导和学习比较复杂。典型的生成式模型有：n元语法模型、HMM、朴素的贝叶斯分类器、概率上下文无关文法等。

判别式模型则符合传统的模式分类思想，认为y由x决定，直接对后验概率p（y|x）进行建模，它从x中提取特征，学习模型参数，使得条件概率符合一定形式的最优。在这类模型中特征可以任意给定，一般特征是通过函数表示的。这种模型的优点是：处理多类问题或分辨某一类与其他类之间的差异时比较灵活，模型简单，容易建立和学习。其弱点在于模型的描述能力有限，变量之间的关系不清楚，而且大多数区分式模型是有监督的学习方法，不能扩展成无监督的学习方法。代表性的区分式模型有：最大熵模型、条件随机场、支持向量机、最大熵马尔可夫模型（maximum-entropy Markov model, MEMM）、感知机（perceptron）等。


贝叶斯网络
贝叶斯网络又称为信度网络或信念网络（belief networks），是一种基于概率推理的数学模型，其理论基础是贝叶斯公式。

形式上，一个贝叶斯网络就是一个有向无环图（directed acyclic graph, DAG），结点表示随机变量，可以是可观测量、隐含变量、未知参量或假设等；结点之间的有向边表示条件依存关系，箭头指向的结点依存于箭头发出的结点（父结点）。两个结点没有连接关系表示两个随机变量能够在某些特定情况下条件独立，而两个结点有连接关系表示两个随机变量在任何条件下都不存在条件独立。条件独立是贝叶斯网络所依赖的一个核心概念。每一个结点都与一个概率函数相关，概率函数的输入是该结点的父结点所表示的随机变量的一组特定值，输出为当前结点表示的随机变量的概率值。

构造贝叶斯网络是一项复杂的任务，涉及表示、推断和学习三个方面的问题。

表示：在某一随机变量的集合x＝{X1，L，Xn}上给出其联合概率分布P。在贝叶斯网络表示中的主要问题是，即使在随机变量仅有两种取值的简单情况下，一个联合概率分布也需要对x1，L，xn的所有2n种不同取值下的概率情况进行说明，这无论从计算代价和人的认知能力方面，还是从统计方法学习如此多参数的可能性方面，几乎都是难以做到或者代价昂贵的事情。

推断：由于贝叶斯网络是变量及其关系的完整模型，因此可以回答关于变量的询问，如当观察到某些变量（证据变量）时，推断另一些变量子集的变化。在已知某些证据的情况下计算变量的后验分布的过程称作概率推理。常用的精确推理方法包括变量消除法（variable elimination）和团树（clique tree）法。变量消除法的基本任务是计算条件概率p（XQ|XE＝x），其中，XQ是询问变量的集合，XE为已知证据的变量集合。其基本思想是通过分步计算不同变量的边缘分布按顺序逐个消除未观察到的非询问变量。团树法使用更全局化的数据结构调度各种操作，以获得更加有益的计算代价。
常用的近似推理算法有重要性抽样法（importance sampling）、随机马尔可夫链蒙特卡罗（Markov chain Monte Carlo, MCMC）模拟法、循环信念传播法（loopy belief propagation）和泛化信念传播法（generalized belief propagation）等。

学习：参数学习的目的是决定变量之间相互关联的量化关系，即依存强度估计。也就是说，对于每个结点X来说，需要计算给定父结点条件下X结点的概率，这些概率分布可以是任意形式的，通常是离散分布或高斯分布。常用的参数学习方法包括最大似然估计法、最大后验概率法、期望最大化方法（EM）和贝叶斯估计方法。在贝叶斯图模型中使用较多的是贝叶斯估计法。

马尔科夫模型
